{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAS/bpx6ucA/bFfFpr53c7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--Tu1WzKU02J"
      },
      "source": [
        "# Experimenting with our own Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V9P0_2fLtub"
      },
      "source": [
        "## TODO:\n",
        "\n",
        "- [x] import CORA dataset\n",
        "- [ ] implement our approach: consider k-hop neighbors' input features and the current node's hidden state\n",
        "- [ ] experiment a first model with GCN as the message passing scheme (later we'll experiment with GAT and GraphSAGE)\n",
        "- [ ] track over-smoothing with **MAD** and **MADGap** over: \n",
        "    - [ ] K hops considered\n",
        "    - [ ] epochs\n",
        "\n",
        "#### Side notes\n",
        "\n",
        "- Try to inverse the k-hop neighbors (start from remote and move down)\n",
        "- Early stop for nodes that don't have k-hop neighbors (just pass the hidden state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HwdZNmrU5YL"
      },
      "source": [
        "## Setup environment\n",
        "\n",
        "- load packages from google drive (to install once)\n",
        "- configure working directory (to download datasets)\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sMxsXleMcJL",
        "outputId": "10ed6465-4901-40dc-f476-460f55fc0d45"
      },
      "source": [
        "# setup colab environment\n",
        "import os, sys\n",
        "import os.path as osp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/mnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lAtppl0VNDF",
        "outputId": "501ba421-f312-442b-e804-c7db587953c5"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/data.py\n",
        "!wget https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/utils.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 14:18:57--  https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/data.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1072 (1.0K) [text/plain]\n",
            "Saving to: â€˜data.pyâ€™\n",
            "\n",
            "\rdata.py               0%[                    ]       0  --.-KB/s               \rdata.py             100%[===================>]   1.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-28 14:18:57 (72.8 MB/s) - â€˜data.pyâ€™ saved [1072/1072]\n",
            "\n",
            "--2021-05-28 14:18:57--  https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2333 (2.3K) [text/plain]\n",
            "Saving to: â€˜utils.pyâ€™\n",
            "\n",
            "utils.py            100%[===================>]   2.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-28 14:18:58 (39.4 MB/s) - â€˜utils.pyâ€™ saved [2333/2333]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpZJSdtcOcmD"
      },
      "source": [
        "# import utility functions\n",
        "from data import load_dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcNfXM8aOs2s"
      },
      "source": [
        "path = osp.join(os.getcwd(), 'data')\n",
        "cora_dataset = load_dataset(path, 'Cora')\n",
        "G = cora_dataset[0] # only graph of the dataset\n",
        "\n",
        "# MAD_cora = mean_average_distance(x=G.x)\n",
        "# MADGap_cora = mean_average_distance_gap(x=G.x, adj_matrix=tg.utils.to_dense_adj(G.edge_index)[0])\n",
        "# print(f'Initial MAD for Cora: {MAD_cora}')\n",
        "# print(f'Initial MADGap for Cora: {MADGap_cora}')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYkeaQUqgn0M"
      },
      "source": [
        "## Understanding data structures\n",
        "\n",
        "ðŸŽ¯ Filter edge_index to keep only the k-hop neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1QJAGApg3kZ"
      },
      "source": [
        "# Cora has only one graph\n",
        "G = cora_dataset[0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf3efFXpg31R",
        "outputId": "6084e6fd-09c6-4bd5-91ba-aa0b179eccbc"
      },
      "source": [
        "# Shape [2, 10556]\n",
        "G.edge_index.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10556])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwOC-fl2hGJD",
        "outputId": "ccac3b8d-7e52-4106-d868-3851b8d08a81"
      },
      "source": [
        "# Look how the edge_index is made\n",
        "for i in range(G.edge_index.size(-1)):\n",
        "    node_i, node_j = G.edge_index[:, i]\n",
        "    print(f\"{node_i} â†’ {node_j}\")\n",
        "\n",
        "    if i == 2: break"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 â†’ 633\n",
            "0 â†’ 1862\n",
            "0 â†’ 2582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nFnLYMihGas"
      },
      "source": [
        "import time\n",
        "from torch_geometric.utils import to_dense_adj, dense_to_sparse"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9zJ6yALhGv_"
      },
      "source": [
        "def filter_neighbors(edge_index, k=1):\n",
        "    \"\"\"Find k-hop neighbors recursevely\n",
        "\n",
        "    Args:\n",
        "        edge_index (tensor): sparse adjacency matrix composed of edge indices\n",
        "        k (int): hop of neighbors to keep (e.g. k=1 is the regular adjacency matrix)\n",
        "    \n",
        "    Returns:\n",
        "        tensor: sparse matrix containing edge indices of the k-hop neighbors\n",
        "    \"\"\"\n",
        "    print(f\"k: {k}\")\n",
        "    \n",
        "    if k==1:\n",
        "        return edge_index\n",
        "    \n",
        "    t_start = time.perf_counter()\n",
        "\n",
        "    # Step 1: get the adjacency matrix\n",
        "    A  = to_dense_adj(edge_index=edge_index)\n",
        "    # Step 2: find k-step neighbors\n",
        "    for i in range(A.size(-2)):\n",
        "        for j in range(A.size(-1)):\n",
        "            if j == i: continue\n",
        "            if A[0, i, j] == 1:\n",
        "                for l in range(A.size(-2)):\n",
        "                    if l == i: continue\n",
        "                    if A[0, j, l] == 1:\n",
        "                        A[0, i, l] = 1\n",
        "    \n",
        "    t_end = time.perf_counter()\n",
        "    print(f\"Time: {t_end - t_start}\")\n",
        "    return filter_neighbors(dense_to_sparse(A), k-1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "kzqL_66HoBXG",
        "outputId": "da938c13-afed-4953-f6c0-7937994f3205"
      },
      "source": [
        "filter_neighbors(G.edge_index, k=3)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-40151e6ca6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilter_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-6774b44dcc26>\u001b[0m in \u001b[0;36mfilter_neighbors\u001b[0;34m(edge_index, k)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                         \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp2rl87UaOqU"
      },
      "source": [
        "\n",
        "## Our Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK_J2lR7WzpT"
      },
      "source": [
        "def xavier(tensor):\n",
        "    \"\"\"Initialize weight matrix with Xavier distribution\n",
        "\n",
        "    Args:\n",
        "        tensor (tensor): weigh matrix\n",
        "    Return:\n",
        "        tensor - weight matrix initialized\n",
        "    \"\"\"\n",
        "    if tensor is not None:\n",
        "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-2)))\n",
        "        tensor.data.uniform_(-stdv, stdv)\n",
        "\n",
        "def zeros(tensor):\n",
        "    \"\"\"Initialize bias vector with all zeros\n",
        "\n",
        "    Args:\n",
        "        tensor (tensor): bias vector\n",
        "    \n",
        "    Return\n",
        "        tensor - bias vector initialized with zeros\n",
        "    \"\"\"\n",
        "    if tensor is not None:\n",
        "        tensor.data.fill_(0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TIrILSGaSmY"
      },
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "\n",
        "class KHopGCNConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, k):\n",
        "        self(KHopNet, self).__init__(aggr='add')\n",
        "        self.k = k\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "        self.reset_parameters()\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        xavier(self.lin.weight)\n",
        "        zeros(self.lin.bias)\n",
        "    \n",
        "    def forward(self, x, h, edge_index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (tensor): node input features, with shape [N, in_channels]\n",
        "            h (tensor): node hidden states, with shape [N, in_channels]\n",
        "            edge_index (tensor): graph edges, with shape [2, E]\n",
        "            k (int): distance from the neighbors\n",
        "        \"\"\"\n",
        "        # Step 1: filter edges to keep only k-hop neighbors\n",
        "        edge_index = filter_neighbors(edge_index, num_nodes=x.size(0), k=self.k)\n",
        "\n",
        "        # Step 2: Linearly transform node feature matrix.\n",
        "        x = self.lin(x)\n",
        "        h = self.lin(h)\n",
        "\n",
        "        # Step 3: Compute normalization.\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Step 4-5: Start propagating messages.\n",
        "        return self.propagate(edge_index, x=x, h=h, norm=norm)\n",
        "    \n",
        "    def message(self, x_i, x_j):\n",
        "        # x_j are input features of the neighbors\n",
        "\n",
        "        # Step 4: Normalize node features.\n",
        "        return nrom.view(-1, 1) * x_j\n",
        "    \n",
        "    def update(self, aggr_out, norm, h):\n",
        "        # Step 5: add target node hidden state and return new node embeddings\n",
        "        aggr_out += norm.view(-1, 1) * h\n",
        "        return aggr_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is7rikSbu18N"
      },
      "source": [
        "### The KHopNet (Our Approach - full model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW9UqE1Tu8wk"
      },
      "source": [
        "class KHopNet(torch.nn.Module):\n",
        "    def __init__(self, dataset, K):\n",
        "        super(KHopNet, self).__init__()\n",
        "        self.conv1 = KHopNetConv(dataset.num_features, dataset.num_features, k=1)\n",
        "        self.conv2 = KHopNetConv(dataset.num_features, dataset.num_features, k=2)\n",
        "        self.conv3 = KHopNetConv(dataset.num_features, dataset.num_classes, k=3)\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "        self.conv3.reset_parameters()\n",
        "    \n",
        "    def forward(self, data, dropout=.3):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=dropout, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4trPmjuwM9k"
      },
      "source": [
        "def train(model, optimizer, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "    \n",
        "    outs = {}\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = data[f'{key}_mask']\n",
        "        loss = F.nll_loss(logits[mask], data.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "        outs[f'{key}_loss'] = loss\n",
        "        outs[f'{key}_acc'] = acc\n",
        "    \n",
        "    return outs\n",
        "\n",
        "def run(dataset, model, runs, epochs, lr, weight_decay, early_stopping):\n",
        "    val_losses, accs, durations = [], [], []\n",
        "    for _ in range(runs):\n",
        "        data = data.to(device)\n",
        "        model.to(device).reset_parameters()\n",
        "        optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        \n",
        "        t_start = time.perf_counter()\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        test_acc = 0\n",
        "        val_loss_history = []\n",
        "\n",
        "        for epoch in range(1, epochs+1):\n",
        "            train(model, optimizer, data)\n",
        "            eval_info = evaluate(model, data)\n",
        "            eval_info['epoch'] = epoch\n",
        "        \n",
        "            if eval_info['val_loss'] < best_val_loss:\n",
        "                best_val_loss = eval_info['val_loss']\n",
        "                test_acc = eval_info['test_acc']\n",
        "            \n",
        "            val_loss_history.append(eval_info['val_loss'])\n",
        "            if early_stopping > 0 and epoch > epochs // 2:\n",
        "                tmp = tensor(val_loss_history[-(early_stopping + 1):-1])\n",
        "                if eval_info['val_loss'] > tmp.mean().item():\n",
        "                    break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_end = time.perf_counter()\n",
        "\n",
        "        val_losses.append(best_val_loss)\n",
        "        accs.append(test_acc)\n",
        "        durations.append(t_end - t_start)\n",
        "\n",
        "    loss, acc, duration = tensor(val_losses), tensor(accs), tensor(durations)\n",
        "\n",
        "    print('Val Loss: {:.4f}, Test Accuracy: {:.3f} Â± {:.3f}, Duration: {:.3f}'.\n",
        "          format(loss.mean().item(),\n",
        "                 acc.mean().item(),\n",
        "                 acc.std().item(),\n",
        "                 duration.mean().item()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}