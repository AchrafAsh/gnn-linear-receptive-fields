{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_khop_with_embeddings.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMfFkn5l0giQJ5a8OPlqeut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef3a32baebca446a8c08028b380a67ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c5c3e6501974df7a34a250a5c9e0436",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d2ddee931f734a528894c91330a86cf7",
              "IPY_MODEL_7f45e6ce560c415cb53068e612b8da5b",
              "IPY_MODEL_c42af0c628ad4ffd8eefa99433eca46d"
            ]
          }
        },
        "7c5c3e6501974df7a34a250a5c9e0436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2ddee931f734a528894c91330a86cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85b21ff7870d4a0d98673dcc5b426e95",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_262a9e10a6b94e50b7505deb6acfeece"
          }
        },
        "7f45e6ce560c415cb53068e612b8da5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4b9d60c43114423beef0601e719ed45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7dc44e22e5a644758e8132ec38f6217e"
          }
        },
        "c42af0c628ad4ffd8eefa99433eca46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78b80aecd66147ecab5771a99802c18b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  1.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54d9be3a794c4244b985ef870127cf93"
          }
        },
        "85b21ff7870d4a0d98673dcc5b426e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "262a9e10a6b94e50b7505deb6acfeece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4b9d60c43114423beef0601e719ed45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7dc44e22e5a644758e8132ec38f6217e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78b80aecd66147ecab5771a99802c18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54d9be3a794c4244b985ef870127cf93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7c12f976be64257aee11c1c93bd981e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65fcacb9e736454096e7f1242f54f290",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b956b9867c024fa2940f193c8d05cd4c",
              "IPY_MODEL_47afd0da5bd94b87a73daeaf777f99ac",
              "IPY_MODEL_1f415e6402c04325b7814c3274f414db"
            ]
          }
        },
        "65fcacb9e736454096e7f1242f54f290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b956b9867c024fa2940f193c8d05cd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d878c493dece437e83bf3eeb77b3109d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0bbb63ba3bb4a4aa40b79bc98d7c46b"
          }
        },
        "47afd0da5bd94b87a73daeaf777f99ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_952a03378c4c4dc7915f75d7dd9765ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03184e5b79124670859bd27d3d2b2530"
          }
        },
        "1f415e6402c04325b7814c3274f414db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b78bcf362ce242d8aef18bfe0bab6e1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/400 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1461fa5b1854ad49bc20560f21a7a23"
          }
        },
        "d878c493dece437e83bf3eeb77b3109d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0bbb63ba3bb4a4aa40b79bc98d7c46b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "952a03378c4c4dc7915f75d7dd9765ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03184e5b79124670859bd27d3d2b2530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b78bcf362ce242d8aef18bfe0bab6e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1461fa5b1854ad49bc20560f21a7a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchrafAsh/gnn-receptive-fields/blob/main/06_khop_with_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sclJ_0n4BFKs"
      },
      "source": [
        "After some reflection (and seeing that our model had way too many parameters), we realised something weird happening in the design of Graph Neural Networks.\n",
        "Most GNNs, if not all, are embedding the input features in the first layer which has a receptive field containing only the direct neighbors.\n",
        "It leads to a very biased embedding (100% attention from the direct neighbors) which could potentially cause a loss of information that is irrelevant for the direct neighbors, but highly relevant for remote ones or even for the task at hand.\n",
        "\n",
        "Because our approach required to compute new embeddings for each k-hop neighborhood, we realised that this was not an ideal way of computing embeddings.\n",
        "\n",
        "In this notebook, we try to design a new Message Passing GNN with an initial MLP that serves as an embedding layer from which we then operate our different convolutional layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKZmfT7qLs-2"
      },
      "source": [
        "## **🚀 Setting up the environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orLdyl_jAdh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb639343-5adc-4d01-c087-1915138fd4d8"
      },
      "source": [
        "import os, sys\n",
        "import os.path as osp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "try:\n",
        "    os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "except:\n",
        "    pass\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/mnt; to attempt to forcibly remount, call drive.mount(\"/content/mnt\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaLdo83XCNT6"
      },
      "source": [
        "# import everything\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from functools import partial\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "from torch_geometric.utils import degree, to_dense_adj, dense_to_sparse, add_self_loops\n",
        "from torch_geometric.nn import GCNConv, MessagePassing, Sequential\n",
        "from torch_sparse import spmm\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9je4QMSYLBXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f091bb-bcc4-48c3-ad95-f096926fdc50"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33machraf\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZFgW_W4Looj"
      },
      "source": [
        "## **🎨 Designing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOwBE0ICew_"
      },
      "source": [
        "# Parameter initialization\n",
        "def xavier(tensor):\n",
        "    if tensor is not None:\n",
        "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-2)))\n",
        "        tensor.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "def zeros(tensor):\n",
        "    if tensor is not None:\n",
        "        tensor.data.fill_(0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfHDhO-ULqOT"
      },
      "source": [
        "#### **Our version of the GCNConv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jQEIzoIIsk8"
      },
      "source": [
        "class OurGCNConv(MessagePassing):\n",
        "    def __init__(self, num_features:int, in_channels:int, out_channels:int, k:int):\n",
        "        super().__init__(aggr='add')  # \"Add\" aggregation\n",
        "        self.k = k\n",
        "        self.lin_input = torch.nn.Linear(num_features, out_channels)\n",
        "        self.lin_hidden = torch.nn.Linear(in_channels, out_channels)\n",
        "        \n",
        "        self.reset_parameters()\n",
        "        \n",
        "    def reset_parameters(self):\n",
        "        xavier(self.lin_input.weight)\n",
        "        zeros(self.lin_input.bias)\n",
        "        \n",
        "        xavier(self.lin_hidden.weight)\n",
        "        zeros(self.lin_hidden.bias)\n",
        "\n",
        "    def forward(self, x, h, edge_index):\n",
        "        # x is the input features and has shape [N, num_features]\n",
        "        # h is the hidden state and has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E] , E being the number of edges\n",
        "\n",
        "        # step 1: linearly transform node feature matrices\n",
        "        x = self.lin_input(x)\n",
        "        h = self.lin_hidden(h)\n",
        "\n",
        "        # step 3-5: start propagating messages\n",
        "        return self.propagate(edge_index[self.k], x=x, h=h)\n",
        "\n",
        "    def message(self, x_j, h_i, edge_index, size):\n",
        "        # x_j is the input features of the neighbors and has shape [E, out_channels] (has already been multiplied by the weight matrix)\n",
        "\n",
        "        # step 3: normalize node features\n",
        "        row, col = edge_index\n",
        "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # out = norm.view(-1, 1) * x_j\n",
        "        out = norm.view(-1, 1) * (x_j + h_i)\n",
        "\n",
        "        return out + h_i\n",
        "        # add the hidden state of the target node\n",
        "        # norm = deg_inv_sqrt[row] * deg_inv_sqrt[row]\n",
        "        \n",
        "        # return out + norm.view(-1, 1) * h_i\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels] is the output of self.message()\n",
        "\n",
        "        # step 5: return new node embeddings\n",
        "        return aggr_out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXHyp3eWLtnC"
      },
      "source": [
        "#### **Our full model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ6WNylDIuw9"
      },
      "source": [
        "# the real deal\n",
        "class OurModel(torch.nn.Module):\n",
        "    def __init__(self, num_layers:int, hidden_dim:int, num_features:int, \n",
        "                 num_classes:int, propagation_steps:int=2, dropout:float=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding input features\n",
        "        self.in_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=num_features, out_features=hidden_dim),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        # Convolutional layers\n",
        "        self.conv_layers = self.create_layers(num_layers=num_layers,\n",
        "                                              hidden_dim=hidden_dim,\n",
        "                                              dropout=dropout)\n",
        "        \n",
        "        # Readout function\n",
        "        self.readout = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=hidden_dim, out_features=num_classes),\n",
        "            torch.nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def create_layers(self, num_layers:int, hidden_dim:int, dropout:float):\n",
        "        layers = [(OurGCNConv(num_features=hidden_dim, in_channels=hidden_dim, out_channels=hidden_dim, k=0), \"x, x, edge_index -> h\"),\n",
        "                (torch.nn.ReLU(inplace=True)),\n",
        "                (torch.nn.Dropout(p=dropout), \"h -> h\")]\n",
        "        \n",
        "        for k in range(1, num_layers):\n",
        "            layers += [\n",
        "                (OurGCNConv(num_features=hidden_dim, in_channels=hidden_dim, out_channels=hidden_dim, k=k), \"x, h, edge_index -> h\"),\n",
        "                # (GCNConv(hidden_dim, hidden_dim), \"h, edge_index -> h\"),\n",
        "                (torch.nn.ReLU(inplace=True)),\n",
        "                (torch.nn.Dropout(p=dropout), \"h -> h\")\n",
        "            ]\n",
        "        return Sequential(\"x, edge_index\", layers)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv_layers.reset_parameters()\n",
        "\n",
        "\n",
        "    def propagate(self, x, edge_index):\n",
        "        # add self loops\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        \n",
        "        # normalize\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # propagate the node features\n",
        "        for _ in range(3):\n",
        "            x = spmm(edge_index, norm.view(-1, 1), x.size(0), x.size(0), x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        embeddings = self.in_mlp(x)\n",
        "        h = self.conv_layers(embeddings, edge_index)\n",
        "        out = self.propagate(h, edge_index[0])\n",
        "        return h, self.readout(out)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNftl2EJKtaS"
      },
      "source": [
        "## **🧰 Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBMGdT6_Cdpg"
      },
      "source": [
        "def get_k_neighbors(k: int):\n",
        "    \"\"\"Returns the l-hop neighbors for l between 1 (the adjacency matrix) and k (given depth)\n",
        "\n",
        "    Args:\n",
        "        - adj: dense adjacency matrix\n",
        "        - k (int): size of the maximum neighborhood\n",
        "    \"\"\"\n",
        "    \n",
        "    output = [G.edge_index]\n",
        "    dense_adj = to_dense_adj(G.edge_index).squeeze(0)\n",
        "    dense_nebs = [dense_adj.clone()]\n",
        "    adj_pow = dense_adj.clone()\n",
        "\n",
        "    for l in tqdm(range(1, k)):\n",
        "        adj_pow = torch.mm(dense_adj, adj_pow)\n",
        "        k_neb = torch.where(\n",
        "            torch.where(adj_pow > 0, 1, 0) - sum(dense_nebs) > 0,\n",
        "            1,\n",
        "            0\n",
        "        )\n",
        "        dense_nebs.append(k_neb)\n",
        "        output.append(dense_to_sparse(k_neb)[0])\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l23anrpnd4Id"
      },
      "source": [
        "def tsne_plot(model: torch.nn.Module, all_edge_index:list, title:str):\n",
        "    # Representing the representations with t-SNE algorithm\n",
        "    h, logits = model(G.x, all_edge_index)\n",
        "    representations = TSNE().fit_transform(h.detach().numpy())\n",
        "    \n",
        "    # Plot the 2-D representations, both with true labels and predictions\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(24, 8))\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "\n",
        "    sns.scatterplot(x=representations[:,0], y=representations[:,1], hue=logits.argmax(dim=1), legend='full', palette=palette, ax=ax[0]).set(title=\"Predictions\")\n",
        "    sns.scatterplot(x=representations[:,0], y=representations[:,1], hue=G.y, legend='full', palette=palette, ax=ax[1]).set(title=\"True labels\")\n",
        "    \n",
        "    fig.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbRr8MlyKunT"
      },
      "source": [
        "# count model parameters\n",
        "def count_parameters(model: torch.nn.Module):\n",
        "    print(f\"The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDFbtutLKIA"
      },
      "source": [
        "def make(config):\n",
        "    # Make the model\n",
        "    model = OurModel(num_layers=config.num_layers, hidden_dim=config.hidden_dim,\n",
        "                    num_features=cora_dataset.num_features,\n",
        "                    num_classes=cora_dataset.num_classes,\n",
        "                    dropout=config.dropout).to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                 lr=config.learning_rate,\n",
        "                                 weight_decay=config.weight_decay)\n",
        "    \n",
        "    return model, criterion, optimizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BjffiwYK3d9"
      },
      "source": [
        "def train(model, all_edge_index, criterion, optimizer, config):\n",
        "    # tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    # Run training and track with wandb\n",
        "    dense_adj = to_dense_adj(G.edge_index).squeeze(0)\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        loss = train_step(model, all_edge_index, optimizer, criterion)\n",
        "        \n",
        "        # test the model\n",
        "        test(model, all_edge_index, criterion,\n",
        "             metrics=[('mad', mad_value),\n",
        "                      ('mad_gap', partial(mad_gap_value,dense_adj)),\n",
        "                      ('mad_sp', shortest_path_mad)])\n",
        "\n",
        "\n",
        "def train_step(model, all_edge_index, optimizer, criterion):\n",
        "    \"\"\"Performs one training step\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    # Forward pass\n",
        "    _, out = model(G.x, all_edge_index)\n",
        "    loss = criterion(out[G.train_mask], G.y[G.train_mask])\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NoRsdlxLQ31"
      },
      "source": [
        "def test(model, all_edge_index, criterion, metrics=[]):\n",
        "    \"\"\"\n",
        "    Metrics is a list of tuple ('metric_name', metric_func) where the metric \n",
        "    function takes the last representation matrix and returns a scalar.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        h, logits = model(G.x, all_edge_index)\n",
        "\n",
        "    outs = {}\n",
        "    for (name, metric) in metrics:\n",
        "        outs[name] = metric(h)\n",
        "\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = G[f'{key}_mask']\n",
        "        loss = criterion(logits[mask], G.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(G.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "        outs[f'{key}_loss'] = loss\n",
        "        outs[f'{key}_acc'] = acc\n",
        "    \n",
        "    wandb.log(outs)\n",
        "    \n",
        "    return outs"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PRqeb7NLFPB"
      },
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "    with wandb.init(project='gnn-receptive-fields', entity='achraf', config=hyperparameters):\n",
        "        config = wandb.config # to make sure we use what is saved in wandb\n",
        "\n",
        "        # create the model\n",
        "        model, criterion, optimizer = make(config)\n",
        "        count_parameters(model)\n",
        "        \n",
        "        # compute different depth edge_index\n",
        "        all_edge_index = get_k_neighbors(config.num_layers)\n",
        "\n",
        "        # train the model\n",
        "        train(model, all_edge_index, criterion, optimizer, config)\n",
        "\n",
        "        tsne_plot(model, all_edge_index, title=\"Last hidden representations\")\n",
        "\n",
        "        # Save the model in the exchangeable ONNX format → not working... yet\n",
        "        # torch.onnx.export(model, G, \"model.onnx\")\n",
        "        # wandb.save(\"model.onnx\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUUzwlcUOsGm"
      },
      "source": [
        "#### Over-smoothing metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Veu6qkPaBz"
      },
      "source": [
        "def mad_value(in_arr, mask_arr=None, distance_metric='cosine', digt_num=4, target_idx=None):\n",
        "    \"\"\"The numpy version for mad (able to compute quickly)\n",
        "\n",
        "    Args:\n",
        "        - in_arr [num_nodes, hidden_dim]: the node feature matrix\n",
        "        - mask_arr [num_nodes, num_nodes]: the mask matrix of the target relations (is it the adjacency matrix?)\n",
        "        - target_idx [1, 2, 3, ...n]: the nodes indices for which we calculate the mad value\n",
        "    \"\"\"\n",
        "\n",
        "    if mask_arr == None:\n",
        "        mask_arr = torch.ones(in_arr.size(0), in_arr.size(0))\n",
        "\n",
        "    dist_arr = pairwise_distances(in_arr, in_arr, metric=distance_metric)\n",
        "    mask_dist = np.multiply(dist_arr, mask_arr)\n",
        "    divide_arr = (mask_dist != 0).sum(1) + 1e-8\n",
        "    \n",
        "    node_dist = mask_dist.sum(1) / divide_arr\n",
        "    if target_idx==None:\n",
        "        mad = node_dist.mean()\n",
        "    else:\n",
        "        node_dist = np.multiply(node_dist,target_idx)\n",
        "        mad = node_dist.sum()/((node_dist!=0).sum()+1e-8)\n",
        "\n",
        "    try:\n",
        "        mad = round(mad, digt_num)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return mad"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpeJIt8VPgDi"
      },
      "source": [
        "def mad_gap_value(adj, in_arr):\n",
        "    \"\"\"Simple version of the MADGap metric implementation\n",
        "\n",
        "    Args:\n",
        "        - in_arr [node_num, hidden_dim]: the node feature matrix\n",
        "        - adj [node_num, node_num]: dense adjacency matrix\n",
        "    \"\"\"\n",
        "\n",
        "    mad_neb = mad_value(in_arr=in_arr, mask_arr=adj)\n",
        "    mad_rmt = mad_value(in_arr=in_arr, mask_arr=1-adj)\n",
        "\n",
        "    return (mad_rmt - mad_neb).item()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgOfrhlBPh5T"
      },
      "source": [
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbFq656zPsRF"
      },
      "source": [
        "def get_shortest_path_lengths():\n",
        "    g = to_networkx(G)\n",
        "    shortest_paths = nx.shortest_path_length(g)\n",
        "\n",
        "    sp_matrix = torch.zeros((G.num_nodes, G.num_nodes), dtype=int)\n",
        "\n",
        "    for node_idx, path_lengths in shortest_paths:\n",
        "        for (idx, len) in path_lengths.items():\n",
        "            sp_matrix[node_idx, idx] = len\n",
        "    \n",
        "    return sp_matrix"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgvayx62P2wJ"
      },
      "source": [
        "shortest_path_lens = get_shortest_path_lengths()\n",
        "shortest_path_mask = torch.where(shortest_path_lens == 0, torch.tensor(0, dtype=torch.float32), 1/shortest_path_lens)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ljcmLuPu3Z"
      },
      "source": [
        "def shortest_path_mad(in_arr):\n",
        "    \"\"\"Computes MAD of all node with shortest path normalization\n",
        "\n",
        "    Args:\n",
        "        - h [num_nodes, num_nodes]: representation matrix\n",
        "    \"\"\"\n",
        "    \n",
        "    return mad_value(in_arr=in_arr,\n",
        "                     mask_arr=shortest_path_mask)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbw0zc9ZLUge"
      },
      "source": [
        "## **🧪 Run experiments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGv90OtKKBF4"
      },
      "source": [
        "#### Import Cora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3rGm6txKDKE"
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/data.py\n",
        "\n",
        "from data import load_dataset\n",
        "\n",
        "path = osp.join(os.getcwd(), 'data')\n",
        "cora_dataset = load_dataset(path, 'Cora')\n",
        "G = cora_dataset[0] # only graph of the dataset\n",
        "palette = sns.color_palette(\"hls\", cora_dataset.num_classes)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWRrea65MFnw"
      },
      "source": [
        "#### Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJnS7eE8LS7q"
      },
      "source": [
        "config = dict(\n",
        "    num_layers=2,\n",
        "    hidden_dim=16,\n",
        "    epochs=400,\n",
        "    learning_rate=0.001,\n",
        "    weight_decay=1e-5,\n",
        "    dropout=0.5)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jKb3rh4LYNU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "ef3a32baebca446a8c08028b380a67ac",
            "7c5c3e6501974df7a34a250a5c9e0436",
            "d2ddee931f734a528894c91330a86cf7",
            "7f45e6ce560c415cb53068e612b8da5b",
            "c42af0c628ad4ffd8eefa99433eca46d",
            "85b21ff7870d4a0d98673dcc5b426e95",
            "262a9e10a6b94e50b7505deb6acfeece",
            "f4b9d60c43114423beef0601e719ed45",
            "7dc44e22e5a644758e8132ec38f6217e",
            "78b80aecd66147ecab5771a99802c18b",
            "54d9be3a794c4244b985ef870127cf93",
            "a7c12f976be64257aee11c1c93bd981e",
            "65fcacb9e736454096e7f1242f54f290",
            "b956b9867c024fa2940f193c8d05cd4c",
            "47afd0da5bd94b87a73daeaf777f99ac",
            "1f415e6402c04325b7814c3274f414db",
            "d878c493dece437e83bf3eeb77b3109d",
            "a0bbb63ba3bb4a4aa40b79bc98d7c46b",
            "952a03378c4c4dc7915f75d7dd9765ce",
            "03184e5b79124670859bd27d3d2b2530",
            "b78bcf362ce242d8aef18bfe0bab6e1e",
            "f1461fa5b1854ad49bc20560f21a7a23"
          ]
        },
        "outputId": "1e882d44-a9f0-4816-dff4-a08e7b997b3b"
      },
      "source": [
        "model = model_pipeline(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.33 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.32<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">deft-field-43</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/achraf/gnn-receptive-fields\" target=\"_blank\">https://wandb.ai/achraf/gnn-receptive-fields</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/achraf/gnn-receptive-fields/runs/2wufj845\" target=\"_blank\">https://wandb.ai/achraf/gnn-receptive-fields/runs/2wufj845</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210712_102423-2wufj845</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The model has 24,151 parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef3a32baebca446a8c08028b380a67ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7c12f976be64257aee11c1c93bd981e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/400 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}