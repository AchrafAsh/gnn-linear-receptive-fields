{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_khop_with_embeddings.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7z2OHz7iHYm902l4wOahl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchrafAsh/gnn-receptive-fields/blob/main/06_khop_with_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sclJ_0n4BFKs"
      },
      "source": [
        "After some reflection (and seeing that our model had way too many parameters), we realised something weird happening in the design of Graph Neural Networks.\n",
        "Most GNNs, if not all, are embedding the input features in the first layer which has a receptive field containing only the direct neighbors.\n",
        "It leads to a very biased embedding (100% attention from the direct neighbors) which could potentially cause a loss of information that is irrelevant for the direct neighbors, but highly relevant for remote ones or even for the task at hand.\n",
        "\n",
        "Because our approach required to compute new embeddings for each k-hop neighborhood, we realised that this was not an ideal way of computing embeddings.\n",
        "\n",
        "In this notebook, we try to design a new Message Passing GNN with an initial MLP that serves as an embedding layer from which we then operate our different convolutional layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKZmfT7qLs-2"
      },
      "source": [
        "## **🚀 Setting up the environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orLdyl_jAdh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f18af4-0562-4443-d672-beb9c289e152"
      },
      "source": [
        "import os, sys\n",
        "import os.path as osp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "try:\n",
        "    os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "except:\n",
        "    pass\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/mnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaLdo83XCNT6"
      },
      "source": [
        "# import everything\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "\n",
        "from functools import partial\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "from torch_geometric.utils import degree, to_dense_adj, dense_to_sparse, add_self_loops, to_networkx\n",
        "from torch_geometric.nn import GCNConv, MessagePassing, Sequential\n",
        "from torch_sparse import spmm\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9je4QMSYLBXt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e5e7b819-bf99-4e64-81f5-5fefde9459ec"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZFgW_W4Looj"
      },
      "source": [
        "## **🎨 Designing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOwBE0ICew_"
      },
      "source": [
        "# Parameter initialization\n",
        "def xavier(tensor):\n",
        "    if tensor is not None:\n",
        "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-2)))\n",
        "        tensor.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "def zeros(tensor):\n",
        "    if tensor is not None:\n",
        "        tensor.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfHDhO-ULqOT"
      },
      "source": [
        "#### **Our version of the GCNConv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jQEIzoIIsk8"
      },
      "source": [
        "class OurGCNConv(MessagePassing):\n",
        "    def __init__(self, num_features:int, in_channels:int, out_channels:int, k:int):\n",
        "        super().__init__(aggr='add')  # \"Add\" aggregation\n",
        "        self.k = k\n",
        "        self.lin_neb = torch.nn.Linear(num_features, out_channels)\n",
        "        self.lin_trgt = torch.nn.Linear(in_channels, out_channels)\n",
        "        \n",
        "        self.reset_parameters()\n",
        "        \n",
        "    def reset_parameters(self):\n",
        "        xavier(self.lin_neb.weight)\n",
        "        zeros(self.lin_neb.bias)\n",
        "        \n",
        "        xavier(self.lin_trgt.weight)\n",
        "        zeros(self.lin_trgt.bias)\n",
        "\n",
        "    def forward(self, x, h, edge_index):\n",
        "        # x is the input features and has shape [N, num_features]\n",
        "        # h is the hidden state and has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E] , E being the number of edges\n",
        "\n",
        "        # step 1: linearly transform node feature matrices\n",
        "        x = self.lin_neb(x)\n",
        "        h = self.lin_trgt(h)\n",
        "\n",
        "        # step 3-5: start propagating messages\n",
        "        return self.propagate(edge_index[self.k].to(device), x=x, h=h)\n",
        "\n",
        "    def message(self, x_j, h_i, edge_index, size):\n",
        "        # x_j is the input features of the neighbors and has shape [E, out_channels] (has already been multiplied by the weight matrix)\n",
        "\n",
        "        # step 3: normalize node features\n",
        "        row, col = edge_index\n",
        "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        out = norm.view(-1, 1) * x_j\n",
        "\n",
        "        return out + h_i\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels] is the output of self.message()\n",
        "\n",
        "        # step 5: return new node embeddings\n",
        "        return aggr_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXHyp3eWLtnC"
      },
      "source": [
        "#### **Our full model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ6WNylDIuw9"
      },
      "source": [
        "# the real deal\n",
        "class OurModel(torch.nn.Module):\n",
        "    def __init__(self, num_layers:int, hidden_dim:int, num_features:int, \n",
        "                 num_classes:int, propagation_steps:int=2, dropout:float=0.5):\n",
        "        super().__init__()\n",
        "        self.propagation_steps = propagation_steps\n",
        "        \n",
        "        self.alpha = torch.nn.Parameter(torch.tensor(0.5), requires_grad=True)\n",
        "        # Embedding input features\n",
        "        self.in_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=num_features, out_features=hidden_dim),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        # Convolutional layers\n",
        "        self.conv_layers = self.create_layers(num_layers=num_layers,\n",
        "                                              hidden_dim=hidden_dim,\n",
        "                                              dropout=dropout)\n",
        "        # Readout function\n",
        "        self.readout = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=hidden_dim, out_features=num_classes),\n",
        "            torch.nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def create_layers(self, num_layers:int, hidden_dim:int, dropout:float):\n",
        "        layers = [(OurGCNConv(num_features=hidden_dim, in_channels=hidden_dim, out_channels=hidden_dim, k=0), \"x, x, edge_index -> h\"),\n",
        "                (torch.nn.ReLU(inplace=True)),\n",
        "                (torch.nn.Dropout(p=dropout), \"h -> h\")]\n",
        "        \n",
        "        for k in range(1, num_layers):\n",
        "            layers += [\n",
        "                (OurGCNConv(num_features=hidden_dim, in_channels=hidden_dim, out_channels=hidden_dim, k=k), \"x, h, edge_index -> h\"),\n",
        "                # (GCNConv(hidden_dim, hidden_dim), \"h, edge_index -> h\"),\n",
        "                (torch.nn.ReLU(inplace=True)),\n",
        "                (torch.nn.Dropout(p=dropout), \"h -> h\")\n",
        "            ]\n",
        "        return Sequential(\"x, edge_index\", layers)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv_layers.reset_parameters()\n",
        "\n",
        "\n",
        "    def propagate(self, x, edge_index):\n",
        "        # add self loops\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        \n",
        "        # normalize\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # GCN propagation scheme\n",
        "        # for _ in range(self.propagation_steps):\n",
        "        #     x = spmm(edge_index, norm, x.size(0), x.size(0), x)\n",
        "        \n",
        "        # return x\n",
        "        \n",
        "        # APPNP propagation scheme\n",
        "        z = x.clone()\n",
        "        for _ in range(self.propagation_steps):\n",
        "            z = spmm(edge_index, norm, x.size(0), x.size(0), z) * (1-self.alpha) + x * self.alpha\n",
        "        return z\n",
        "\n",
        "        # another propagation scheme (sum of the powers of A)\n",
        "        # props = []\n",
        "        # for _ in range(self.propagation_steps):\n",
        "        #     x= spmm(edge_index, norm, x.size(0), x.size(0), x)\n",
        "        #     props.append(x)\n",
        "        # return sum(props)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        embeddings = self.in_mlp(x)\n",
        "        h = self.conv_layers(embeddings, edge_index)\n",
        "        out = self.propagate(h, edge_index[0].to(device))\n",
        "        return h, self.readout(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNftl2EJKtaS"
      },
      "source": [
        "## **🧰 Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBMGdT6_Cdpg"
      },
      "source": [
        "def get_k_neighbors(k: int):\n",
        "    \"\"\"Returns the l-hop neighbors for l between 1 (the adjacency matrix) and k (given depth)\n",
        "\n",
        "    Args:\n",
        "        - adj: dense adjacency matrix\n",
        "        - k (int): size of the maximum neighborhood\n",
        "    \"\"\"\n",
        "    \n",
        "    output = [G.edge_index]\n",
        "    dense_adj = to_dense_adj(G.edge_index).squeeze(0)\n",
        "    dense_nebs = [dense_adj.clone()]\n",
        "    adj_pow = dense_adj.clone()\n",
        "\n",
        "    for l in tqdm(range(1, k)):\n",
        "        adj_pow = torch.mm(dense_adj, adj_pow)\n",
        "        k_neb = torch.where(\n",
        "            torch.where(adj_pow > 0, 1, 0) - sum(dense_nebs) > 0,\n",
        "            1,\n",
        "            0\n",
        "        )\n",
        "        dense_nebs.append(k_neb)\n",
        "        output.append(dense_to_sparse(k_neb)[0])\n",
        "    \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l23anrpnd4Id"
      },
      "source": [
        "def tsne_plot(model: torch.nn.Module, all_edge_index:list, title:str):\n",
        "    # Representing the representations with t-SNE algorithm\n",
        "    h, logits = model(G.x, all_edge_index)\n",
        "    representations = TSNE().fit_transform(h.cpu().detach().numpy())\n",
        "    \n",
        "    # Plot the 2-D representations, both with true labels and predictions\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(24, 8))\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "\n",
        "    sns.scatterplot(x=representations[:,0], y=representations[:,1], hue=logits.cpu().detach().argmax(dim=1), legend='full', palette=palette, ax=ax[0]).set(title=\"Predictions\")\n",
        "    sns.scatterplot(x=representations[:,0], y=representations[:,1], hue=G.y.cpu().detach().numpy(), legend='full', palette=palette, ax=ax[1]).set(title=\"True labels\")\n",
        "    \n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbRr8MlyKunT"
      },
      "source": [
        "# count model parameters\n",
        "def count_parameters(model: torch.nn.Module):\n",
        "    print(f\"The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDFbtutLKIA"
      },
      "source": [
        "def make(config):\n",
        "    # Make the model\n",
        "    model = OurModel(num_layers=config.num_layers, hidden_dim=config.hidden_dim,\n",
        "                     num_features=cora_dataset.num_features,\n",
        "                     num_classes=cora_dataset.num_classes,\n",
        "                     propagation_steps=config.propagation_steps,\n",
        "                     dropout=config.dropout).to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                 lr=config.learning_rate,\n",
        "                                 weight_decay=config.weight_decay)\n",
        "    \n",
        "    return model, criterion, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BjffiwYK3d9"
      },
      "source": [
        "def train(model, all_edge_index, criterion, optimizer, config):\n",
        "    # tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    # Run training and track with wandb\n",
        "    dense_adj = to_dense_adj(G.edge_index).squeeze(0)\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        loss = train_step(model, all_edge_index, optimizer, criterion)\n",
        "        \n",
        "        # test the model\n",
        "        test(model, all_edge_index, criterion)\n",
        "            #  metrics=[('mad', mad_value),\n",
        "            #           ('mad_gap', partial(mad_gap_value,dense_adj)),\n",
        "            #           ('mad_sp', shortest_path_mad)])\n",
        "\n",
        "\n",
        "def train_step(model, all_edge_index, optimizer, criterion):\n",
        "    \"\"\"Performs one training step\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    # Forward pass\n",
        "    _, out = model(G.x.to(device), all_edge_index)\n",
        "    loss = criterion(out[G.train_mask], G.y[G.train_mask])\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NoRsdlxLQ31"
      },
      "source": [
        "def test(model, all_edge_index, criterion, metrics=[]):\n",
        "    \"\"\"\n",
        "    Metrics is a list of tuple ('metric_name', metric_func) where the metric \n",
        "    function takes the last representation matrix and returns a scalar.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        h, logits = model(G.x, all_edge_index)\n",
        "\n",
        "    outs = {}\n",
        "    for (name, metric) in metrics:\n",
        "        outs[name] = metric(h)\n",
        "\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = G[f'{key}_mask']\n",
        "        loss = criterion(logits[mask], G.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(G.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "        outs[f'{key}_loss'] = loss\n",
        "        outs[f'{key}_acc'] = acc\n",
        "    \n",
        "    wandb.log(outs)\n",
        "    \n",
        "    return outs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PRqeb7NLFPB"
      },
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "    with wandb.init(project='gnn-receptive-fields', entity='achraf', config=hyperparameters):\n",
        "        config = wandb.config # to make sure we use what is saved in wandb\n",
        "\n",
        "        # create the model\n",
        "        model, criterion, optimizer = make(config)\n",
        "        count_parameters(model)\n",
        "        \n",
        "        # compute different depth edge_index\n",
        "        all_edge_index = get_k_neighbors(config.num_layers)\n",
        "\n",
        "        # train the model\n",
        "        train(model, all_edge_index, criterion, optimizer, config)\n",
        "\n",
        "        tsne_plot(model, all_edge_index, title=\"Last hidden representations\")\n",
        "\n",
        "        # Save the model in the exchangeable ONNX format → not working... yet\n",
        "        # torch.onnx.export(model, G, \"model.onnx\")\n",
        "        # wandb.save(\"model.onnx\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGv90OtKKBF4"
      },
      "source": [
        "#### Import Cora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3rGm6txKDKE"
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/data.py\n",
        "\n",
        "from data import load_dataset\n",
        "\n",
        "path = osp.join(os.getcwd(), 'data')\n",
        "cora_dataset = load_dataset(path, 'Cora')\n",
        "G = cora_dataset[0].to(device) # only graph of the dataset\n",
        "palette = sns.color_palette(\"hls\", cora_dataset.num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUUzwlcUOsGm"
      },
      "source": [
        "#### Over-smoothing metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Veu6qkPaBz"
      },
      "source": [
        "def mad_value(in_arr, mask_arr=None, distance_metric='cosine', digt_num=4, target_idx=None):\n",
        "    \"\"\"The numpy version for mad (able to compute quickly)\n",
        "\n",
        "    Args:\n",
        "        - in_arr [num_nodes, hidden_dim]: the node feature matrix\n",
        "        - mask_arr [num_nodes, num_nodes]: the mask matrix of the target relations (is it the adjacency matrix?)\n",
        "        - target_idx [1, 2, 3, ...n]: the nodes indices for which we calculate the mad value\n",
        "    \"\"\"\n",
        "\n",
        "    if mask_arr == None:\n",
        "        mask_arr = torch.ones(in_arr.size(0), in_arr.size(0))\n",
        "\n",
        "    dist_arr = pairwise_distances(in_arr, in_arr, metric=distance_metric)\n",
        "    mask_dist = np.multiply(dist_arr, mask_arr)\n",
        "    divide_arr = (mask_dist != 0).sum(1) + 1e-8\n",
        "    \n",
        "    node_dist = mask_dist.sum(1) / divide_arr\n",
        "    if target_idx==None:\n",
        "        mad = node_dist.mean()\n",
        "    else:\n",
        "        node_dist = np.multiply(node_dist,target_idx)\n",
        "        mad = node_dist.sum()/((node_dist!=0).sum()+1e-8)\n",
        "\n",
        "    try:\n",
        "        mad = round(mad, digt_num)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return mad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpeJIt8VPgDi"
      },
      "source": [
        "def mad_gap_value(adj, in_arr):\n",
        "    \"\"\"Simple version of the MADGap metric implementation\n",
        "\n",
        "    Args:\n",
        "        - in_arr [node_num, hidden_dim]: the node feature matrix\n",
        "        - adj [node_num, node_num]: dense adjacency matrix\n",
        "    \"\"\"\n",
        "\n",
        "    mad_neb = mad_value(in_arr=in_arr, mask_arr=adj)\n",
        "    mad_rmt = mad_value(in_arr=in_arr, mask_arr=1-adj)\n",
        "\n",
        "    return (mad_rmt - mad_neb).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbFq656zPsRF"
      },
      "source": [
        "def get_shortest_path_lengths():\n",
        "    g = to_networkx(G)\n",
        "    shortest_paths = nx.shortest_path_length(g)\n",
        "\n",
        "    sp_matrix = torch.zeros((G.num_nodes, G.num_nodes), dtype=int)\n",
        "\n",
        "    for node_idx, path_lengths in shortest_paths:\n",
        "        for (idx, len) in path_lengths.items():\n",
        "            sp_matrix[node_idx, idx] = len\n",
        "    \n",
        "    return sp_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgvayx62P2wJ"
      },
      "source": [
        "shortest_path_lens = get_shortest_path_lengths()\n",
        "shortest_path_mask = torch.where(shortest_path_lens == 0, torch.tensor(0, dtype=torch.float32), 1/shortest_path_lens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ljcmLuPu3Z"
      },
      "source": [
        "def shortest_path_mad(in_arr):\n",
        "    \"\"\"Computes MAD of all node with shortest path normalization\n",
        "\n",
        "    Args:\n",
        "        - h [num_nodes, num_nodes]: representation matrix\n",
        "    \"\"\"\n",
        "    \n",
        "    return mad_value(in_arr=in_arr,\n",
        "                     mask_arr=shortest_path_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbw0zc9ZLUge"
      },
      "source": [
        "## **🧪 Run experiments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWRrea65MFnw"
      },
      "source": [
        "#### Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJnS7eE8LS7q"
      },
      "source": [
        "config = dict(\n",
        "    num_layers=1,\n",
        "    hidden_dim=16,\n",
        "    propagation_steps=20,\n",
        "    epochs=400,\n",
        "    learning_rate=0.001,\n",
        "    weight_decay=1e-5,\n",
        "    dropout=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jKb3rh4LYNU"
      },
      "source": [
        "model = model_pipeline(config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}