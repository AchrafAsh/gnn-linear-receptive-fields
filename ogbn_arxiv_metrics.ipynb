{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ogbn-arxiv_metrics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0EY46Hyh+WLIoJhKk/2zg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchrafAsh/gnn-receptive-fields/blob/main/ogbn_arxiv_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7tgkwigrKEQ",
        "outputId": "8083fc8c-182d-4647-e403-d763c1b71fb6"
      },
      "source": [
        "import os, sys\n",
        "import os.path as osp\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "try:\n",
        "    os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "except:\n",
        "    pass\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/mnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pqIlPkJrLZl"
      },
      "source": [
        "import time\n",
        "import concurrent.futures\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "from collections import Counter\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_theme(font_scale=1.8)\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjKb8YwzrNEg"
      },
      "source": [
        "def clamp(x: torch.Tensor):\n",
        "    if not x.is_coalesced(): x = x.coalesce()\n",
        "\n",
        "    mask = (x._values() > 0).nonzero().view(-1)\n",
        "    values = x._values().index_select(0, mask).clamp(0, 1)\n",
        "    indices = x._indices().index_select(1, mask)\n",
        "\n",
        "    return torch.sparse_coo_tensor(indices, values, x.shape).coalesce()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4TEXEDIrP40"
      },
      "source": [
        "def sparse_hop_neighbors(k:int, edge_index: torch.Tensor, num_nodes:int):\n",
        "    # transform edge_index into a sparse tensor\n",
        "    yield edge_index, edge_index\n",
        "\n",
        "    if k > 1:\n",
        "        sparse_edge_index = torch.sparse_coo_tensor(edge_index, torch.ones(edge_index.size(1)), (num_nodes, num_nodes))\n",
        "        cum_neighbors = neighbors = pow_A = sparse_edge_index.clone()\n",
        "\n",
        "    for _ in range(1, k):\n",
        "        pow_A = clamp(torch.sparse.mm(sparse_edge_index, pow_A))\n",
        "        neighbors = clamp(pow_A - cum_neighbors)\n",
        "        cum_neighbors = (cum_neighbors + neighbors).coalesce()\n",
        "        \n",
        "        yield neighbors.indices(), cum_neighbors.indices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARd6SKQurQSq"
      },
      "source": [
        "def get_neighbors(edge_index:torch.Tensor, i:int):\n",
        "    first_indices = (edge_index[0] == i).nonzero().view(-1)\n",
        "    second_indices = (edge_index[1] == i).nonzero().view(-1)\n",
        "\n",
        "    first_neb_indices = edge_index[1][first_indices]\n",
        "    second_neb_indices = edge_index[1][second_indices]\n",
        "    \n",
        "    neb_indices = torch.cat((\n",
        "        first_neb_indices,\n",
        "        second_neb_indices),\n",
        "        0\n",
        "    )\n",
        "\n",
        "    indices = torch.unique(neb_indices, sorted=True)\n",
        "    return indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbuy73VZrQbi"
      },
      "source": [
        "def scale(X:torch.Tensor):   \n",
        "    m = X.mean(0)\n",
        "    s = X.std(0)\n",
        "    ones = torch.ones(s.shape).to(device)\n",
        "    s = torch.where(s == 0, ones, s)\n",
        "    return (X - m)/ s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW88obYFrQlQ"
      },
      "source": [
        "def centroids(X:torch.Tensor, y:torch.Tensor):\n",
        "    \"\"\"Returns the label representation by averaging its nodes' features\n",
        "\n",
        "    Args:\n",
        "        - X [num_nodes, num_features]: node features\n",
        "        - y [num_nodes]: labels\n",
        "    \"\"\"\n",
        "    num_classes = y.max().item() + 1\n",
        "    \n",
        "    # group nodes by label\n",
        "    obs = {}\n",
        "    for i in range(X.size(0)):\n",
        "        if obs.get(y[i].item()):\n",
        "            obs[y[i].item()] += [X[i]]\n",
        "        else:\n",
        "            obs[y[i].item()] = [X[i]]\n",
        "\n",
        "    return torch.stack([sum(obs[c]) / len(obs[c]) for c in range(num_classes)], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovntWdv8rQvZ"
      },
      "source": [
        "def homophily_index(y:torch.Tensor, edge_index:torch.tensor):\n",
        "    \"\"\"Computes the homophily index\n",
        "    Args:\n",
        "        - y [num_nodes]: labels of all nodes\n",
        "        - edge_index: sparse adjacency matrix\n",
        "    \"\"\"\n",
        "    num_nodes = y.size(0)\n",
        "\n",
        "    return torch.stack(\n",
        "        [(y[get_neighbors(edge_index, i)] == y[i]).float().mean() \n",
        "        if get_neighbors(edge_index, i).size(0) > 0 else torch.tensor(0.).to(device) \n",
        "        for i in range(num_nodes)]\n",
        "        , 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtM0A96WrQ5b"
      },
      "source": [
        "def corr(x, y, i):\n",
        "    if x.size(0) == 0: return torch.tensor(0., device=device)\n",
        "    cov = torch.einsum('ij, j -> i', x, y)\n",
        "    norm = torch.mm(x, x.t()).diag().sqrt() * torch.matmul(y, y).sqrt()\n",
        "    return cov / norm\n",
        "\n",
        "def graph_correlation(edge_index:torch.Tensor, x:torch.Tensor, y:torch.Tensor, y_mean:torch.Tensor):\n",
        "    \"\"\"Returns the list of correlations between the barycenter representation of\n",
        "    labels and the neighbor features.\n",
        "\n",
        "    Args:\n",
        "        - edge_index - sparse adjacency matrix\n",
        "        - x [num_nodes, num_features]: node features\n",
        "        - y [num_nodes, num_features]: label representation associated with the target node\n",
        "        :rtype: list [num_nodes]: correlation (scalar) for every node\n",
        "    \"\"\"\n",
        "\n",
        "    num_nodes = x.size(0)\n",
        "    y_scaled = y.sub(y_mean)\n",
        "\n",
        "    return torch.stack(\n",
        "        [corr(x=x[get_neighbors(edge_index, i)], y=y_scaled[i], i=i).abs().mean()\n",
        "        for i in range(num_nodes)]\n",
        "        , 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZtoi-cqrRDZ"
      },
      "source": [
        "def count_neighbors(edge_index:torch.Tensor, num_nodes:int):\n",
        "    return torch.stack(\n",
        "        [get_neighbors(edge_index, i).size(0) for i in range(num_nodes)],\n",
        "        0).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYzxeLtprRND"
      },
      "source": [
        "def confidence(values: torch.Tensor):\n",
        "    \"\"\"Returns the 95% confidence interval of the array of values\n",
        "    \"\"\"\n",
        "    q = 1.96\n",
        "    m = values.mean()\n",
        "    s = values.std()\n",
        "    \n",
        "    return m - q * s/np.sqrt(len(values)), m + q * s/np.sqrt(len(values))\n",
        "\n",
        "\n",
        "def graph_summary(dataset, K=10):\n",
        "    graph = dataset[0].to(device)\n",
        "    \n",
        "    x = scale(graph.x)\n",
        "    scaled_centroids = centroids(x, graph.y)\n",
        "    y = torch.stack([scaled_centroids[graph.y[i]] for i in range(graph.num_nodes)]).to(device)\n",
        "    y_mean = scaled_centroids.mean(0)\n",
        "\n",
        "    data = pd.DataFrame({'k': [],\n",
        "                         'homophily_neighbors':[],\n",
        "                         'homophily_neighborhood':[],\n",
        "                         'correlation_neighbors':[],\n",
        "                         'correlation_neighborhood':[],\n",
        "                         'neighbors_count':[],\n",
        "                         'neighborhood_count':[]})\n",
        "\n",
        "    idx, k = 0, 0\n",
        "    for neighbors, cum_neighbors in tqdm(\n",
        "        sparse_hop_neighbors(K+1, graph.edge_index, graph.num_nodes),\n",
        "        total=K):\n",
        "\n",
        "        k += 1\n",
        "        # measure graph properties\n",
        "        homo_neighbors_conf = confidence(homophily_index(y=graph.y, edge_index=neighbors))\n",
        "        homo_neighborhood_conf = confidence(homophily_index(y=graph.y, edge_index=cum_neighbors))\n",
        "        \n",
        "        corr_neighbors_conf = confidence(graph_correlation(neighbors, x=x, y=y, y_mean=y_mean))\n",
        "        corr_neighborhood_conf = confidence(graph_correlation(cum_neighbors, x=x, y=y, y_mean=y_mean))\n",
        "        \n",
        "        neighbors_count = count_neighbors(neighbors, graph_num_nodes)\n",
        "        neighborhood_count = count_neighbors(cum_neighbors, graph_num_nodes)\n",
        "\n",
        "        data.loc[idx] = {'k':k,\n",
        "                         'homophily_neighbors':homo_neighbors_conf[0].item(),\n",
        "                         'homophily_neighborhood':homo_neighborhood_conf[0].item(),\n",
        "                         'correlation_neighbors':corr_neighbors_conf[0].item(),\n",
        "                         'correlation_neighborhood':corr_neighborhood_conf[0].item(),\n",
        "                         'neighborhood_count':neighborhood_count.min().item(),\n",
        "                         'neighbors_count':neighbors_count.min().item()}\n",
        "        idx += 1\n",
        "        data.loc[idx] = {'k':k,\n",
        "                         'homophily_neighbors':homo_neighbors_conf[1].item(),\n",
        "                         'homophily_neighborhood':homo_neighborhood_conf[1].item(),\n",
        "                         'correlation_neighbors':corr_neighbors_conf[1].item(),\n",
        "                         'correlation_neighborhood':corr_neighborhood_conf[1].item(),\n",
        "                         'neighborhood_count':neighborhood_count.max().item(),\n",
        "                         'neighbors_count':neighbors_count.max().item()}\n",
        "        idx += 1\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRV0-1RyrRaV"
      },
      "source": [
        "def plot_summary(data):\n",
        "    _, ax = plt.subplots(1, 3, figsize=(32,8))\n",
        "    lineplot1 = sns.lineplot(ax=ax[0], x='k', y='value', \n",
        "                             hue='variable',\n",
        "                             style='variable',\n",
        "                             markers=True,\n",
        "                             data=pd.melt(data[['k', 'homophily_neighbors', 'homophily_neighborhood']], ['k']))\n",
        "    lineplot1.set(xlabel=\"depth\", ylabel=\"index\", title=\"Homophily\")\n",
        "    lineplot1.legend(('neighbors', 'neighborhood'), frameon=False).set_title(None)\n",
        "\n",
        "    lineplot2 = sns.lineplot(ax=ax[1], x='k', y='value',\n",
        "                             hue='variable',\n",
        "                             style='variable',\n",
        "                             markers=True,\n",
        "                             data=pd.melt(data[['k', 'correlation_neighbors', 'correlation_neighborhood']], ['k']))\n",
        "    lineplot2.set(xlabel=\"depth\", ylabel=\"correlation\", title=\"Correlation\")\n",
        "    lineplot2.legend(('neighbors', 'neighborhood'), frameon=False).set_title(None)\n",
        "\n",
        "    lineplot3 = sns.lineplot(ax=ax[2], x='k', y='value',\n",
        "                             hue='variable',\n",
        "                             style='variable',\n",
        "                             markers=True,\n",
        "                             data=pd.melt(data[['k', 'neighbors_count', 'neighborhood_count']], ['k']))\n",
        "    lineplot3.set(xlabel=\"depth\", ylabel=\"count\", title=\"Neighbors count\")\n",
        "    lineplot3.legend(('neighbors', 'neighborhood'), loc=\"upper left\", frameon=False).set_title(None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76tpCROhsJXJ"
      },
      "source": [
        "%%capture\n",
        "!pip install ogb\n",
        "\n",
        "from torch_geometric.transforms import ToSparseTensor\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "\n",
        "dataset = PygNodePropPredDataset(name='ogbn-arxiv',\n",
        "                                 transform=ToSparseTensor())\n",
        "\n",
        "data = dataset[0]\n",
        "data.edge_index = data.adj_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ga0wyNDrRj_"
      },
      "source": [
        "summary = graph_summary([data], K=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}